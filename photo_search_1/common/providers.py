# providers.py
import os
import json
import base64
import time
from pathlib import Path
from typing import Dict, List, Tuple, Iterable, Optional

import numpy as np
import requests
from PIL import Image, ExifTags

# ------------- çŽ¯å¢ƒé…ç½® -------------
from dotenv import load_dotenv
load_dotenv()

DATA_DIR = Path(os.getenv("DATA_DIR", "./data")).resolve()
DATA_DIR.mkdir(parents=True, exist_ok=True)

PHOTO_DIR = Path(os.getenv("PHOTO_DIR", "./photos")).resolve()
OLLAMA_BASE = os.getenv("OLLAMA_BASE", "http://127.0.0.1:11434")
CAPTION_MODEL = os.getenv("CAPTION_MODEL", "gemma3:4b")
EMBED_MODEL = os.getenv("EMBED_MODEL", "mxbai-embed-large")  # ä¹Ÿå¯ bge-m3 ç­‰

JSONL_PATH = DATA_DIR / "photos.jsonl"
INDEX_PATH = DATA_DIR / "index.faiss"
IDMAP_PATH = DATA_DIR / "id_map.json"     # id -> (path, caption, shot_time) çš„æ˜ å°„
DIM_PATH = DATA_DIR / "dim.txt"           # è®°å½•å‘é‡ç»´åº¦

# ------------- FAISSï¼ˆå¯é€‰ï¼‰-------------
_FAISS_OK = True
try:
    import faiss  # type: ignore
except Exception:
    _FAISS_OK = False

# å…¨å±€çŠ¶æ€ï¼šå° demo ç›´æŽ¥ç”¨
_index = None                      # FAISS index æˆ– None
_id_list: List[str] = []           # å‘é‡é¡ºåºå¯¹åº”çš„ id åˆ—è¡¨
_meta: Dict[str, Dict] = {}        # id -> {path, caption, shot_time}

# ------------- å·¥å…·å‡½æ•° -------------
def _now_iso() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%S", time.localtime())

def _normalize(v: np.ndarray) -> np.ndarray:
    # ä½™å¼¦æ£€ç´¢ï¼šç”¨å†…ç§¯ & å•ä½åŒ–
    n = np.linalg.norm(v, axis=1, keepdims=True) + 1e-12
    return v / n

def _load_meta() -> None:
    """ä»Ž JSONL å’Œ id_map.json åˆå§‹åŒ–å†…å­˜æ˜ å°„ï¼ˆé¦–æ¬¡åŠ è½½ï¼‰"""
    global _meta, _id_list
    _meta = {}
    _id_list = []
    if IDMAP_PATH.exists():
        _meta = json.loads(IDMAP_PATH.read_text(encoding="utf-8"))
        _id_list = list(_meta.keys())
    elif JSONL_PATH.exists():
        # é¦–æ¬¡æž„å»º id_map
        with JSONL_PATH.open("r", encoding="utf-8") as f:
            for line in f:
                if not line.strip():
                    continue
                rec = json.loads(line)
                rid = rec["id"]
                _meta[rid] = {
                    "path": rec["path"],
                    "caption": rec.get("caption", ""),
                    "shot_time": rec.get("shot_time"),
                }
                _id_list.append(rid)
        IDMAP_PATH.write_text(json.dumps(_meta, ensure_ascii=False, indent=2), encoding="utf-8")

def _save_meta_line(rec: Dict) -> None:
    """å‘ JSONL è¿½åŠ ä¸€è¡Œï¼Œå¹¶åŒæ­¥ id_map.json"""
    with JSONL_PATH.open("a", encoding="utf-8") as f:
        f.write(json.dumps(rec, ensure_ascii=False) + "\n")
    _meta[rec["id"]] = {
        "path": rec["path"],
        "caption": rec.get("caption", ""),
        "shot_time": rec.get("shot_time"),
    }
    _id_list.append(rec["id"])
    IDMAP_PATH.write_text(json.dumps(_meta, ensure_ascii=False, indent=2), encoding="utf-8")

def extract_exif_datetime(path: str) -> Optional[str]:
    """å°½é‡ä»Ž EXIF èŽ·å–æ‹æ‘„æ—¶é—´ï¼ˆISO å­—ç¬¦ä¸²ï¼‰"""
    try:
        im = Image.open(path)
        exif = im.getexif()
        if not exif:
            return None
        dt_str = None
        for tag_id, val in exif.items():
            tag = ExifTags.TAGS.get(tag_id, tag_id)
            if tag in ("DateTimeOriginal", "DateTime"):
                dt_str = str(val)
                break
        if dt_str:
            # å¸¸è§ EXIF å½¢å¦‚ 2023:05:12 10:21:00
            dt_str = dt_str.replace("-", ":")
            y, m, d = dt_str.split(" ")[0].split(":")
            t = dt_str.split(" ")[1]
            return f"{y}-{m}-{d}T{t}"
    except Exception:
        return None
    return None

# ------------- Ollama -------------
def embed_text(text: str) -> np.ndarray:
    """è°ƒç”¨ Ollama embeddings æŽ¥å£ï¼ŒæŠŠæ–‡æœ¬è½¬å‘é‡"""
    payload = {"model": EMBED_MODEL, "prompt": text}
    r = requests.post(f"{OLLAMA_BASE}/api/embeddings", json=payload, timeout=120)
    r.raise_for_status()
    vec = r.json().get("embedding") or r.json().get("embeddings")
    if isinstance(vec, list) and isinstance(vec[0], (float, int)):
        arr = np.array([vec], dtype="float32")
    elif isinstance(vec, list) and isinstance(vec[0], list):
        arr = np.array(vec, dtype="float32")
    else:
        raise RuntimeError("Invalid embeddings response from Ollama")
    return arr  # shape (1, d)
# å‚è€ƒï¼šOllama embeddings æŽ¥å£ä¸Žç¤ºä¾‹ã€‚ [oai_citation:8â€¡ollama.apidog.io](https://ollama.apidog.io/examples-14809545e0?utm_source=chatgpt.com) [oai_citation:9â€¡Ollama](https://ollama.com/blog/embedding-models?utm_source=chatgpt.com) [oai_citation:10â€¡Stack Overflow](https://stackoverflow.com/questions/79364221/what-is-the-right-way-to-generate-ollama-embeddings?utm_source=chatgpt.com)

def caption_image(image_path: str) -> str:
    """ç”¨ Gemma3:4Bï¼ˆæˆ–å…¶ä»–å¤šæ¨¡æ€ï¼‰ç”Ÿæˆä¸€å¥è¯å›¾åƒæè¿°"""
    with open(image_path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    payload = {
        "model": CAPTION_MODEL,
        "prompt": "è¯·ç”¨ä¸€å¥è¯æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚",
        "images": [b64],
        "stream": False,
    }
    r = requests.post(f"{OLLAMA_BASE}/api/generate", json=payload, timeout=180)
    r.raise_for_status()
    return (r.json().get("response") or "").strip()
# å®˜æ–¹æç¤ºï¼šREST API å¯åœ¨ images å‚æ•°ä¸­ä¼  base64 å›¾åƒã€‚ [oai_citation:11â€¡Ollama](https://ollama.com/blog/vision-models?utm_source=chatgpt.com)

# ------------- ç´¢å¼• -------------
def _create_index(dim: int):
    """åˆ›å»ºæˆ–åŠ è½½ FAISS ç´¢å¼•ï¼ˆå†…ç§¯æ£€ç´¢ï¼‰ï¼Œå¹¶è®°å½•ç»´åº¦"""
    global _index
    if _FAISS_OK:
        if INDEX_PATH.exists():
            _index = faiss.read_index(str(INDEX_PATH))
        else:
            _index = faiss.IndexFlatIP(dim)  # å†…ç§¯
            faiss.write_index(_index, str(INDEX_PATH))
        DIM_PATH.write_text(str(dim), encoding="utf-8")
    else:
        _index = None  # å°†èµ° numpy é€€åŒ–æ£€ç´¢

def _load_index_if_needed(dim: int):
    global _index
    if _index is None:
        _create_index(dim)

def _add_to_index(vecs: np.ndarray):
    """æŠŠå‘é‡å¢žé‡åŠ å…¥ç´¢å¼•ï¼ˆè‡ªåŠ¨å•ä½åŒ–ï¼‰"""
    if vecs.ndim == 1:
        vecs = vecs[None, :]
    vecs = vecs.astype("float32")
    vecs = _normalize(vecs)

    if _FAISS_OK:
        faiss.normalize_L2(vecs)  # åŒä¿é™©
        _index.add(vecs)
        faiss.write_index(_index, str(INDEX_PATH))
    else:
        # æ—  faiss æ—¶ï¼Œä»…æŠŠå‘é‡å­˜åˆ° .npy åšé€€åŒ–æ£€ç´¢
        V_PATH = DATA_DIR / "vectors.npy"
        if V_PATH.exists():
            old = np.load(V_PATH)
            new = np.vstack([old, vecs])
            np.save(V_PATH, new)
        else:
            np.save(V_PATH, vecs)

def _vectors_all() -> np.ndarray:
    """é€€åŒ–æ£€ç´¢ï¼šåŠ è½½æ‰€æœ‰å·²å­˜å‘é‡"""
    V_PATH = DATA_DIR / "vectors.npy"
    if V_PATH.exists():
        return np.load(V_PATH)
    return np.zeros((0, int(DIM_PATH.read_text() or "0")), dtype="float32")

def ensure_loaded():
    """é¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½å…ƒæ•°æ®ä¸Žç´¢å¼•"""
    _load_meta()
    # å°è¯•ä»Ž dim.txt èŽ·å–ç»´åº¦ï¼›æ²¡æœ‰å°±ç­‰ç¬¬ä¸€æ¬¡ embed æ—¶å†™å…¥
    if DIM_PATH.exists():
        dim = int(DIM_PATH.read_text().strip())
        if dim > 0:
            _load_index_if_needed(dim)

# ------------- å¯¹å¤–ï¼šæž„å»º & æŸ¥è¯¢ -------------
def build_records(paths: List[str], use_vision: bool = False) -> Iterable[str]:
    """
    æž„å»º/è¿½åŠ ç´¢å¼•ï¼šé’ˆå¯¹ç»™å®šå›¾ç‰‡ç»å¯¹è·¯å¾„åˆ—è¡¨
    é€æ¡ yield æ—¥å¿—ï¼ˆä¾› Gradio æ–‡æœ¬æ¡†æµå¼æ˜¾ç¤ºï¼‰
    """
    if not paths:
        yield "âš ï¸ æ²¡æœ‰é€‰æ‹©ä»»ä½•å›¾ç‰‡ã€‚"
        return

    ensure_loaded()
    yield f"ðŸ“ æœ¬æ¬¡å…± {len(paths)} å¼ ï¼Œå¼€å§‹æž„å»ºç´¢å¼•â€¦"

    ok = 0
    dim_written = DIM_PATH.exists()
    for p in paths:
        try:
            p = str(p)
            if not os.path.exists(p):
                yield f"âŒ è·³è¿‡ï¼šè·¯å¾„ä¸å­˜åœ¨ {p}"
                continue

            rid = Path(p).stem + "_" + str(int(time.time() * 1000))
            shot_time = extract_exif_datetime(p)
            caption = caption_image(p) if use_vision else Path(p).stem

            vec = embed_text(caption)  # (1, d)
            d = vec.shape[1]

            # é¦–æ¬¡å†™å…¥è®°å½•ç»´åº¦ï¼ŒéšåŽåŠ è½½/åˆ›å»ºç´¢å¼•
            if not dim_written:
                _create_index(d)
                dim_written = True
            else:
                _load_index_if_needed(d)

            _add_to_index(vec)
            rec = {
                "id": rid,
                "path": p,
                "shot_time": shot_time,
                "caption": caption,
                "vec": None,  # å‘é‡ä¸æ”¾ JSONLï¼ŒèŠ‚çœç©ºé—´ï¼›å¦‚éœ€å¯æ”¹ä¸º list(vec[0].tolist())
                "created_at": _now_iso(),
            }
            _save_meta_line(rec)
            ok += 1
            yield f"âœ… å·²å…¥åº“ï¼š{Path(p).name} | {caption[:40]}"
        except Exception as e:
            yield f"âŒ å¤±è´¥ï¼š{Path(p).name} | {e}"

    yield f"ðŸŽ‰ å®Œæˆï¼šæˆåŠŸ {ok}/{len(paths)}"

def search_topk(query: str, k: int = 24) -> List[Tuple[str, str]]:
    """æŸ¥è¯¢ï¼šè¿”å›ž (image_path, caption) åˆ—è¡¨ä¾› Gallery"""
    if not query.strip():
        return []
    q = embed_text(query)  # (1, d)
    d = q.shape[1]
    _load_index_if_needed(d)

    if _FAISS_OK and _index is not None and _index.ntotal > 0:
        q = _normalize(q.astype("float32"))
        # faiss å†…éƒ¨ä¹Ÿä¼š normalize_L2ï¼Œè¿™é‡Œç»Ÿä¸€
        faiss.normalize_L2(q)
        scores, idxs = _index.search(q, min(k, len(_id_list)))
        order = idxs[0]
    else:
        # é€€åŒ–ï¼šnumpy è®¡ç®—æ‰€æœ‰å†…ç§¯
        V = _vectors_all()
        if V.shape[0] == 0:
            return []
        qn = _normalize(q.astype("float32"))
        Vn = _normalize(V)
        sims = (Vn @ qn[0].T).reshape(-1)
        order = np.argsort(-sims)[: min(k, len(_id_list))]

    results: List[Tuple[str, str]] = []
    for i in order:
        if i < 0 or i >= len(_id_list):
            continue
        rid = _id_list[i]
        meta = _meta.get(rid)
        if not meta:
            continue
        p = meta["path"]
        if os.path.exists(p):
            results.append((p, meta.get("caption") or ""))
    return results